 % !TeX root = ../main.tex

\chapter{CATFlow: 基于数据一元论抽象的分布式训练策略自动发现框架}

\section{本章概述}

深度神经网络（Deep Neural Networks, DNN），尤其是大语言模型（Large Language Models, LLM），在自然语言处理、计算机视觉等众多领域取得了突破性进展。然而，随着模型参数规模的指数级增长，训练这些模型所需的计算资源和显存容量已远超单个加速器（如GPU、TPU）的物理极限。因此，分布式训练成为大模型研发的必要手段。在分布式环境中，如何将计算任务和模型状态高效地映射到物理设备集群上，即确定最优的并行计划（Parallel Plan），是提升系统效率的核心挑战。

传统的分布式训练策略主要依赖于系统专家的手工设计。例如，Megatron-LM 提出的 3D 并行（结合数据并行、张量并行和流水线并行）已成为行业标准。然而，随着硬件架构的异构化（如多级互联拓扑）和模型结构的多样化（如 MoE、长序列模型），手工设计最优策略的难度呈几何级数上升。为了解决这一问题，学术界提出了多种自动并行化框架，如 Alpa、FlexFlow 和 Unity。这些系统通常采用“以算子为中心”（Operator-Centric）的抽象，将神经网络建模为计算图，通过搜索算法决定算子的切分和调度。

尽管现有的自动并行化方法在一定程度上减轻了人工负担，但它们在表达能力上存在本质局限。以算子为中心的抽象倾向于将数据移动（通信）视为算子调度的副作用，难以显式地建模和优化复杂的数据流行为。例如，上一章介绍的 WeiPipe 策略涉及权重的循环流动，而 ZeRO 系列策略涉及对张量生命周期的精细控制（如参数的暂时驻留和梯度的延迟规约）。这些涉及细粒度数据轨迹和生命周期管理的优化策略，在纯算子图的抽象下难以被直观表达，更难以被自动搜索发现。

针对上述局限，本章提出了一个核心的反向洞察：并行计划本质上是对数据时空轨迹的描述，而非算子的调度安排。基于这一“数据一元论”（Data-Monistic）视角，我们提出了 CATFlow 框架。在 CATFlow 中，计算不再是第一性的操作，而是被隐式定义为一种约束：当所需的输入张量在同一时空坐标汇聚时，计算自然发生。通过引入约束感知张量（Constraint-Aware Tensor, CAT）作为系统的基本图元，我们将并行策略的搜索问题转化为对张量时空轨迹的约束求解问题。

与传统框架采用“加法式”构建（即从基础策略逐步添加并行操作）不同，CATFlow 采用了“减法式”（Subtractive）的空间构建方法。系统初始假设一个包含所有合法数据轨迹的通用全集，用户通过添加约束逐步裁剪掉不可行的区域。这种方法使得搜索空间天然包含了那些人类专家未曾显式定义的策略，为发现反直觉的新型高效策略提供了可能。

本章的主要贡献总结如下：
\begin{enumerate}
    \item \textbf{数据一元论抽象与并行空间}：提出了 CATFlow 框架，通过约束感知张量（CAT）和显式的数据流原语，构建了完备的并行策略搜索空间。相比于传统的算子中心方法，该抽象能够表达更广泛的并行模式，特别是涉及复杂通信和存储优化的策略。
    \item \textbf{新颖训练计划的自动发现}：基于减法式空间构建和势能下降（Potential Energy Descent）搜索算法，实现了对复杂并行策略的自动探索。该方法不仅能复现现有的经典策略，还能自动发现人类专家未曾设想的优化方案。
    \item \textbf{发明用于大模型训练的新计划}：利用 CATFlow 框架，本研究自动发现了两种优于现有 ZeRO-3 的新策略——ZeRO-3.5（权重驻留策略）和 ZeRO-4（梯度延迟规约策略）。实验表明，ZeRO-4 在保持低显存占用的同时，相比 ZeRO-3 实现了最高 39.1\% 的吞吐量提升；同时，自动发现的卸载策略相比传统 ZeRO-Offload 提升了 89.4\% 的吞吐量。
\end{enumerate}

\section{背景与动机}

\subsection{分布式训练策略的演进与挑战}
随着深度学习模型向万亿参数规模迈进，单设备的计算能力和存储容量已成为显著瓶颈。为了训练这些巨型模型，工业界和学术界发展出了一系列复杂的分布式并行策略。
早期的策略主要集中在数据并行（Data Parallelism, DP），通过在多个设备上复制模型副本来加速训练。然而，随着模型显存占用的增加，单纯的 DP 已无法容纳大模型。
为了解决显存限制，模型并行（Model Parallelism）应运而生，包括将张量切分到不同设备的张量并行（Tensor Parallelism, TP）和将模型层分段的流水线并行（Pipeline Parallelism, PP）。
近年来，ZeRO（Zero Redundancy Optimizer）系列技术通过去除数据并行中的状态冗余，进一步降低了显存门槛。
目前，最先进的训练系统（如 Megatron-LM、DeepSpeed）通常混合使用上述多种策略（即 3D 并行），以在显存容量、计算效率和通信带宽之间寻求平衡。

然而，随着硬件环境的日益复杂（如异构计算单元、多层级存储、非均匀互联拓扑）和模型架构的不断创新（如 MoE、长序列 Attention），手工设计最优并行策略变得异常困难。
专家不仅需要深入理解模型的数据依赖关系，还需要精通底层硬件的通信特性和存储层级。
这种高度依赖专家经验的设计模式具有不可扩展性，且难以适应快速变化的软硬件环境。

\subsection{现有自动并行化方法的局限性}
为了降低分布式训练的门槛，自动并行化（Automatic Parallelism）成为研究热点。
现有的自动并行化框架（如 Alpa、FlexFlow、Unity、nnScaler）试图通过搜索算法自动寻找最优的并行策略。
这些框架大多采用“以算子为中心”（Operator-Centric）的抽象，将神经网络建模为由算子（Operator）组成的计算图，并行策略被定义为算子的切分（Sharding）、复制（Replication）或调度（Scheduling）。

尽管这些方法在一定程度上实现了自动化，但它们在表达能力上存在本质的局限性，主要体现在以下两个方面：

\textbf{1. 难以表达复杂的数据流协同优化}：
在算子中心的抽象中，数据移动（通信）通常被视为算子切分后的“副作用”（Side Effect），由系统自动插入通信原语（如 All-Reduce、All-Gather）。
这种隐式的通信管理方式难以表达那些“数据主导”的优化策略。
例如，上一章提出的 WeiPipe 策略，其核心在于让权重在设备间循环流动，而非传统的激活值传递。
又如 ZeRO-Offload，涉及将优化器状态和参数在 GPU 与 CPU 之间进行精细的换入换出。
这些策略要求对数据的流动轨迹进行显式、精确的控制，而算子中心的抽象缺乏相应的描述原语。

\textbf{2. 缺乏对张量生命周期的精细管理}：
现有的框架通常假设张量的生命周期由其依赖的算子决定（即在生产者算子完成后创建，在所有消费者算子完成后销毁）。
然而，许多高效的优化策略需要打破这一假设。
例如，本文发现的 ZeRO-3.5 策略利用了反向传播阶段显存空闲的特性，将权重的生命周期延长（Persist）至下一个 Step 的前向传播，从而消除了冗余通信。
这种对张量生命周期的主动干预（如提前预取、延迟释放、持久化驻留）在纯算子图中难以直观表达。

\subsection{迈向数据一元论抽象}
上述局限性的根源在于，现有的抽象将“计算”视为第一性，而将“数据”视为依附于计算的从属品。
然而，在分布式系统中，数据的存储位置和传输轨迹往往才是决定性能的关键因素（即“Data Movement is the Bottleneck”）。

基于此，本文提出了一种视角的转换：从“以算子为中心”转向“数据一元论”（Data-Monistic）。
在数据一元论的视角下，并行计划本质上是对数据在时空维度上轨迹的描述。
计算不再是显式的操作，而是被隐式定义为一种约束：当所需的输入数据在特定的时间和地点汇聚时，计算自然发生。
这种抽象将计算、存储和通信统一在一个框架下，使得我们能够显式地规划数据的时空轨迹，从而为发现更复杂、更高效的并行策略（如涉及细粒度流水线、异构存储卸载、通信掩盖的策略）提供了理论基础和表达能力。


\section{数据一元论抽象体系}

为了克服以算子为中心抽象的局限性，CATFlow 引入了一种全新的表示方法——约束感知张量（Constraint-Aware Tensor, CAT）。这一抽象体系建立在“数据一元论”的基础之上，将并行计划的本质还原为数据在时空维度上的轨迹规划。

\subsection{约束感知张量（CAT）}
CAT 是 CATFlow 框架中的基本图元，它不仅仅代表计算图中的静态数据块，更封装了数据在整个生命周期内的动态行为。一个 CAT 可以形式化地定义为一个包含三个核心要素的元组：
\begin{itemize}
    \item \textbf{张量实体（Tensor Entity）}：代表计算图中的数据对象，包括持久化的模型参数（Parameters）、瞬时的中间激活值（Activations）以及梯度（Gradients）。
    \item \textbf{时空坐标（Space-Time Coordinate）}：定义了张量存在的物理位置和逻辑时间。
    \begin{itemize}
        \item \textbf{空间坐标}：不仅包含 GPU 设备 ID，还扩展到了 CPU 内存、NVMe 存储等层级，支持异构存储的统一建模。
        \item \textbf{时间坐标}：采用 Lamport 逻辑时间戳（Logical Timestamp），反映了计算图执行的因果顺序（Causal Order），而非物理时钟时间。
    \end{itemize}
    \item \textbf{约束集合（Constraint Set）}：规定了张量与其时空坐标之间的关系，决定了张量“何时”在“何地”存在。
    \begin{itemize}
        \item \textbf{张量内约束（Intra-tensor Constraint）}：限制单个张量在不同时空坐标间的轨迹，负责管理其生命周期（创建、销毁）和移动（传输、复制）。
        \item \textbf{张量间约束（Inter-tensor Constraint）}：定义了多个张量之间的依赖关系。例如，计算操作被建模为一种约束：所有输入张量必须在同一时空坐标汇聚，才能触发输出张量的生成。
    \end{itemize}
\end{itemize}

\subsection{轨迹向量表示}
在 CATFlow 中，我们使用一系列有序的**约束点（Constraint Points）**组成的**约束向量（Constraint Vector）**来描述一个 CAT 的完整时空轨迹。
例如，对于 Transformer 模型中前馈网络（FFN）层的某个激活值张量 $A$，其轨迹可以表示为：
\begin{equation}
    C_{A} = [(\text{Device}_2, t_1), (\text{Device}_2, t_2), (\text{Device}_3, t_3)]
\end{equation}
该向量清晰地描述了张量 $A$ 的生命历程：它在逻辑时间 $t_1$ 于设备 2 上被生成；在 $t_1$ 到 $t_2$ 期间驻留在设备 2 上（可能参与了本地计算）；随后在 $t_3$ 时刻被传输到设备 3 以供后续消费。

这种表示方法的关键优势在于，它将“计算”定义为“数据共存”的自然结果，而不是将“数据移动”视为“算子调度”的副作用。这种视角的逆转使得 CATFlow 能够表达任意复杂的协同优化策略，包括那些传统框架无法描述的细粒度数据流控制。

\section{策略空间构建与原语设计}

基于数据一元论抽象，CATFlow 构建了一个完备且灵活的并行策略搜索空间。

\subsection{减法式空间构建（Subtractive Methodology）}
传统的自动并行化框架通常采用“加法式”构建方法，即从一个基础的单设备执行计划开始，尝试应用各种预定义的并行变换（如切分、流水线化）。这种方法的搜索空间受限于已知变换的组合，难以发现全新的策略。

CATFlow 采用了“减法式”构建方法。我们首先假设一个包含所有合法数据轨迹的“全集”空间。在这个空间中，任何数据可以在任何时间出现在任何设备上，只要满足最基本的数据依赖约束。然后，通过应用原语施加约束，逐步“裁剪”掉不可行（如显存溢出）或低效（如通信瓶颈）的轨迹。这种方法生成的搜索空间天然包含了已知和未知的策略，为发现 ZeRO-3.5 和 ZeRO-4 等新型策略提供了可能。

\subsection{操作原语体系}
为了在搜索空间中进行高效操作，CATFlow 提供了一组高级原语，分为三类：

\subsubsection{张量分布原语（Tensor Distribution Primitives）}
用于控制张量在空间上的分布和移动：
\begin{itemize}
    \item \texttt{split(tensor, split\_vector)}: 将张量沿指定维度切分为多个子张量。这隐式地定义了算子的并行分区（如张量并行）。
    \item \texttt{assign(tensor, devices)}: 强制指定张量在特定时间段内驻留在某些设备上。这直接控制了数据的空间轨迹（隐式定义了算子的放置）。
    \item \texttt{copy(src\_tensor, copy\_num, path)}: 将源张量复制为多个副本，用于实现参数服务器模式或 All-Gather 通信。
    \item \texttt{reduce(tensors, path)}: 显式指定数据的收集或规约操作，用于处理梯度聚合等场景。
\end{itemize}

\subsubsection{依赖管理原语（Dependency Management Primitives）}
用于控制张量在时间上的依赖和顺序：
\begin{itemize}
    \item \texttt{order(event1, event2)}: 强制定义两个事件（如张量的生成或释放）之间的特定顺序。这是实现 ZeRO-3.5 的关键，通过强制推迟权重的释放时间，使其驻留至下一个前向传播阶段。
    \item \texttt{redirect(tensor1, tensor2, tensor3)}: 修改张量间的数据流向，转移依赖关系。这可用于实现重计算（Re-computation）或复杂的环状通信模式。
\end{itemize}

\subsubsection{策略空间划定原语（Strategy-Space Delineation Primitives）}
用于辅助搜索算法裁剪空间：
\begin{itemize}
    \item \texttt{domain}: 指定原语配置（如设备位置或时间步）的允许值范围。
    \item \texttt{not}: 显式排除某些特定的并行计划（例如，禁止将关键路径上的张量卸载到 CPU）。
\end{itemize}


\section{并行计划发现 (Parallelism Plan Discovery)}

\subsection{基于约束的势能下降搜索 (Constraint-Based Potential Descent Search)}

对张量时空轨迹的细粒度控制以及雕刻策略空间的“减法”式方法，可能导致一个更大的搜索空间。虽然这对于包含涌现策略（emergent strategies）并为启发式搜索创建一个更连通、分辨率更高的景观是有利的，但也内在增加了搜索的复杂性。因此，在原语声明阶段对空间进行有偏的缩减，不仅是必要的，而且在引导搜索方面起着至关重要的作用。我们并不声称我们的方法能够从所有可能性的全集中自动找到最优策略。对这种数据一元论搜索空间的属性（例如，这种统一抽象是否增强了拓扑的光滑性和连续性）进行严格的数学分析，也超出了本文的范围。相反，本节提出了一个从 CAT 视角出发的可行搜索算法。该算法在发现新颖策略方面的有效性将在第 7 节中进行实证演示。

该搜索算法受到势场法（potential-field methods）的启发。它将组合优化问题重构为在势场中寻找最小能量状态的过程。核心在于，我们为每个 CAT 分配一个势能函数；然后每个 CAT 贪婪地迁移或转换到一个能降低其自身势能的状态。一个简单的说明性例子：假设 CAT1 当前位于设备 1 上。如果我们定义 CAT1 的势能为该设备上已被占用的内存，那么 CAT1 将倾向于迁移到占用率较低（空闲内存更多）的设备。对每个 CAT 重复这种贪婪最小化过程，会产生一个相当平衡的内存分布。

然而，实际场景要复杂得多。一个策略包含许多 CAT，每个 CAT 包含由多个事件组成的约束向量。尽管每个事件可以独立调度，但事件之间可能存在复杂的依赖关系。因此，我们的搜索算法采用了两级势能定义，每一级都配有其自身的一组可搜索动作（即下一步搜索移动）。

\textbf{一级势能（Level-1 potential）}附加到单个事件上。在一个具体计划中，事件的时空坐标是固定的；因此，其势能由该坐标下底层硬件的资源压力来量化。对于事件 $E$：

\begin{equation}
P(E)=\alpha\frac{d_{c}(E)}{C-U_{c}}+\beta\frac{d_{m}(E)}{M-U_{m}}+\gamma\frac{d_{b}(E)}{B-U_{b}}
\end{equation}

其中 $d_{c}(E)$、$d_{m}(E)$ 和 $d_{b}(E)$ 分别表示事件对计算、内存和带宽的需求；$C$、$M$ 和 $B$ 是设备容量；$U_{c}$、$U_{m}$ 和 $U_{b}$ 是同一设备上其他事件的瞬时使用量；而 $\alpha, \beta, \gamma$ 是标量系数。用户可以自定义势能函数以反映优化目标；例如，当高存储利用率不是目标时，只要不发生溢出，内存压力就可以设为零。

\textbf{二级势能（Level-2 potential）}与单个 CAT 相关联，包含三个部分：固有项（intrinsic）、修正项（corrective）和吸引项（attractive）。固有项是对 CAT 约束向量 $C=(E_{1},E_{2},...,E_{n})$ 中事件级势能的求和。修正项加上了通过张量间约束（inter-CAT constraints）耦合的其他 CAT 所属事件的总势能。吸引项倾向于将 CAT 保留在某个设备上，如果未来的 CAT 依赖于从该 CAT 派生的数据。这种设计提供了全局感知，而无需在每一步动作时模拟端到端性能。对于 CAT $T$，累积势能定义为：

\begin{equation}
P(T)=\sum_{i=1}^{n}P(E_{i})+\sum_{T^{\prime}\in\mathcal{A}(T)}\sum_{j=1}^{m}P(E_{j}^{\prime})+\delta A_{attr}(T)
\end{equation}

其中 $\sum P(E_{i})$ 是 $T$ 的固有势能，$\mathcal{A}(T)$ 是所有通过张量间约束与 $T$ 关联的 CAT 集合，$A_{attr}(T)$ 是通过计算同一设备上依赖于 $T$（且依赖相同数据）的未来 CAT 的开始时间与当前 $T$ 的结束时间之间的正差值之和得出的。

针对 CAT 的搜索动作分为三类：
\begin{enumerate}
    \item 修改约束向量中的单个事件——移动是原子的以处理事件间约束，最佳改变遵循该事件一级势能的最速下降方向（GenerateEventCandidates）；
    \item 通过在张量轨迹中删除或插入事件来改变向量的维度（GenerateVectorCandidates）；
    \item 对整个 CAT 应用宏观调度（split, copy, reduce）（GenerateMacroCandidates）。
\end{enumerate}

可用的变换是从允许的高级策略中枚举出来的。这些类别的并集构成了 CAT 下一步移动的候选集。算法 2 实例化了该搜索，它是贪婪且迭代的。从从空间中采样的初始策略开始，每次迭代计算每个 CAT 的势能，找到其最佳的下一步移动（最大势能下降），然后全局选择下降幅度最大的 CAT 并提交其移动。该过程重复直到满足停止条件。

\texttt{GenerateEventCandidates} 的细节如算法 3 所示。设备候选项从空间邻接中枚举；时间候选项是紧接的前序或后序位置。对于每个事件，该例程枚举相邻设备和时间的笛卡尔积，评估每一对上的事件势能，并在保留所有约束的同时选择最速下降对。

\subsection{代表性的新发现计划 (Representative Newly Discovered Plans)}

在本节中，我们介绍由 CATFlow 自动发现的两个代表性策略：ZeRO-3.5 和 ZeRO-4（详细的搜索分析在第 7.3 节）。相比于 ZeRO-3（在整个训练过程中对权重进行分片，因此在前向和反向传递中都需要 all-gather 来组装完整权重），ZeRO-3.5 在反向传递期间不对收集到的权重进行重新分片（reshard）。相反，这些收集到的权重被保留并在下一个累积步骤的前向传递中重用，从而消除了前向 all-gather 通信。如图 4(c) 所示，在反向传递期间，ZeRO-3.5 回收逐步释放的激活值（activations）所占用的内存，并利用它来保存收集到的权重分片；当总激活内存超过总权重内存时，ZeRO-3.5 在实现与 ZeRO-3 相同的峰值内存的同时，消除了前向 all-gather 通信（图 4(b) 中的 1 block/step）。

在 ZeRO-3.5 的基础上，ZeRO-4 进一步选择性地推迟梯度的 reduce-scatter 操作（在 CATFlow 中通过 \texttt{order($A[j]^{ms+1}\{-1\}, G[j]^{ms}\{0\}$)} 实现）。这允许部分梯度在反向传播期间保留在本地设备上，而不是立即进行通信；reduce-scatter 被推迟到下一次前向传递。如图 4(d) 所示，在反向传播期间，激活值被逐步释放，释放出的内存用于容纳收集到的权重和推迟的梯度。在随后的前向传递中，梯度被归约，权重被丢弃，以释放内存用于新生成的激活值。在图 4(d) 中，我们每三层保留两层的梯度（选择 $j$ 为 3 的倍数）；实际上，$j$ 可以根据实际资源使用情况进行调整。ZeRO-4 实现了比 ZeRO-3.5 更均衡的反向-前向通信模式（图 4(d) 中的 0.67 block/step），这可以从更好的通信-计算重叠中受益。第 7 节展示了 CATFlow 发现的更多计划。

% \section{自动发现的新型策略：ZeRO-3.5 与 ZeRO-4}

% \subsection{ ZeRO-3.5：权重驻留策略}

% \subsection{ ZeRO-4：梯度延迟规约策略}

% \section{卸载策略}

% \section{实验评估}

% \section{本章小结}